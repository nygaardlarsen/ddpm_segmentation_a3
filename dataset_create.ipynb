{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95326c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import zoom as scizoom\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import ctypes\n",
    "from scipy.ndimage import map_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d42b8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def disk(radius, alias_blur=0.1, dtype=np.float32):\n",
    "    if radius <= 8:\n",
    "        L = np.arange(-8, 8 + 1)\n",
    "        ksize = (3, 3)\n",
    "    else:\n",
    "        L = np.arange(-radius, radius + 1)\n",
    "        ksize = (5, 5)\n",
    "    X, Y = np.meshgrid(L, L)\n",
    "    aliased_disk = np.array((X ** 2 + Y ** 2) <= radius ** 2, dtype=dtype)\n",
    "    aliased_disk /= np.sum(aliased_disk)\n",
    "\n",
    "    # supersample disk to antialias\n",
    "    return cv2.GaussianBlur(aliased_disk, ksize=ksize, sigmaX=alias_blur)\n",
    "\n",
    "\n",
    "# modification of https://github.com/FLHerne/mapgen/blob/master/diamondsquare.py\n",
    "def plasma_fractal(mapsize=256, wibbledecay=3):\n",
    "    \"\"\"\n",
    "    Generate a heightmap using diamond-square algorithm.\n",
    "    Return square 2d array, side length 'mapsize', of floats in range 0-255.\n",
    "    'mapsize' must be a power of two.\n",
    "    \"\"\"\n",
    "    assert (mapsize & (mapsize - 1) == 0)\n",
    "    maparray = np.empty((mapsize, mapsize), dtype=np.float64)\n",
    "    maparray[0, 0] = 0\n",
    "    stepsize = mapsize\n",
    "    wibble = 100\n",
    "\n",
    "    def wibbledmean(array):\n",
    "        return array / 4 + wibble * np.random.uniform(-wibble, wibble, array.shape)\n",
    "\n",
    "    def fillsquares():\n",
    "        \"\"\"For each square of points stepsize apart,\n",
    "           calculate middle value as mean of points + wibble\"\"\"\n",
    "        cornerref = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n",
    "        squareaccum = cornerref + np.roll(cornerref, shift=-1, axis=0)\n",
    "        squareaccum += np.roll(squareaccum, shift=-1, axis=1)\n",
    "        maparray[stepsize // 2:mapsize:stepsize,\n",
    "        stepsize // 2:mapsize:stepsize] = wibbledmean(squareaccum)\n",
    "\n",
    "    def filldiamonds():\n",
    "        \"\"\"For each diamond of points stepsize apart,\n",
    "           calculate middle value as mean of points + wibble\"\"\"\n",
    "        mapsize = maparray.shape[0]\n",
    "        drgrid = maparray[stepsize // 2:mapsize:stepsize, stepsize // 2:mapsize:stepsize]\n",
    "        ulgrid = maparray[0:mapsize:stepsize, 0:mapsize:stepsize]\n",
    "        ldrsum = drgrid + np.roll(drgrid, 1, axis=0)\n",
    "        lulsum = ulgrid + np.roll(ulgrid, -1, axis=1)\n",
    "        ltsum = ldrsum + lulsum\n",
    "        maparray[0:mapsize:stepsize, stepsize // 2:mapsize:stepsize] = wibbledmean(ltsum)\n",
    "        tdrsum = drgrid + np.roll(drgrid, 1, axis=1)\n",
    "        tulsum = ulgrid + np.roll(ulgrid, -1, axis=0)\n",
    "        ttsum = tdrsum + tulsum\n",
    "        maparray[stepsize // 2:mapsize:stepsize, 0:mapsize:stepsize] = wibbledmean(ttsum)\n",
    "\n",
    "    while stepsize >= 2:\n",
    "        fillsquares()\n",
    "        filldiamonds()\n",
    "        stepsize //= 2\n",
    "        wibble /= wibbledecay\n",
    "\n",
    "    maparray -= maparray.min()\n",
    "    return maparray / maparray.max()\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor):\n",
    "    h = img.shape[0]\n",
    "    # ceil crop height(= crop width)\n",
    "    ch = int(np.ceil(h / float(zoom_factor)))\n",
    "\n",
    "    top = (h - ch) // 2\n",
    "    img = scizoom(img[top:top + ch, top:top + ch], (zoom_factor, zoom_factor, 1), order=1)\n",
    "    # trim off any extra pixels\n",
    "    trim_top = (img.shape[0] - h) // 2\n",
    "\n",
    "    return img[trim_top:trim_top + h, trim_top:trim_top + h]\n",
    "\n",
    "\n",
    "# # /////////////// End Corruption Helpers ///////////////\n",
    "\n",
    "\n",
    "# # /////////////// Corruptions ///////////////\n",
    "\n",
    "def gaussian_noise(x, severity=1):\n",
    "    c = [.08, .12, 0.18, 0.26, 0.38][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(x + np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
    "\n",
    "\n",
    "def shot_noise(x, severity=1):\n",
    "    c = [60, 25, 12, 5, 3][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(np.random.poisson(x * c) / float(c), 0, 1) * 255\n",
    "\n",
    "\n",
    "def impulse_noise(x, severity=1):\n",
    "    c = [.03, .06, .09, 0.17, 0.27][severity - 1]\n",
    "\n",
    "    x = sk.util.random_noise(np.array(x) / 255., mode='s&p', amount=c)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def speckle_noise(x, severity=1):\n",
    "    c = [.15, .2, 0.35, 0.45, 0.6][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    return np.clip(x + x * np.random.normal(size=x.shape, scale=c), 0, 1) * 255\n",
    "\n",
    "\n",
    "def gaussian_blur(x, severity=1):\n",
    "    c = [1, 2, 3, 4, 6][severity - 1]\n",
    "\n",
    "    x = gaussian(np.array(x) / 255., sigma=c)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def glass_blur(x, severity=1):\n",
    "    # sigma, max_delta, iterations\n",
    "    c = [(0.7, 1, 2), (0.9, 2, 1), (1, 2, 3), (1.1, 3, 2), (1.5, 4, 2)][severity - 1]\n",
    "\n",
    "    x = np.uint8(gaussian(np.array(x) / 255., sigma=c[0]) * 255)\n",
    "\n",
    "    # locally shuffle pixels\n",
    "    for i in range(c[2]):\n",
    "        for h in range(224 - c[1], c[1], -1):\n",
    "            for w in range(224 - c[1], c[1], -1):\n",
    "                dx, dy = np.random.randint(-c[1], c[1], size=(2,))\n",
    "                h_prime, w_prime = h + dy, w + dx\n",
    "                # swap\n",
    "                x[h, w], x[h_prime, w_prime] = x[h_prime, w_prime], x[h, w]\n",
    "\n",
    "    return np.clip(gaussian(x / 255., sigma=c[0]), 0, 1) * 255\n",
    "\n",
    "\n",
    "def defocus_blur(x, severity=1):\n",
    "    c = [(3, 0.1), (4, 0.5), (6, 0.5), (8, 0.5), (10, 0.5)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    kernel = disk(radius=c[0], alias_blur=c[1])\n",
    "\n",
    "    channels = []\n",
    "    for d in range(3):\n",
    "        channels.append(cv2.filter2D(x[:, :, d], -1, kernel))\n",
    "    channels = np.array(channels).transpose((1, 2, 0))  # 3x224x224 -> 224x224x3\n",
    "\n",
    "    return np.clip(channels, 0, 1) * 255\n",
    "\n",
    "\n",
    "\n",
    "def zoom_blur(x, severity=1):\n",
    "    c = [np.arange(1, 1.11, 0.01),\n",
    "         np.arange(1, 1.16, 0.01),\n",
    "         np.arange(1, 1.21, 0.02),\n",
    "         np.arange(1, 1.26, 0.02),\n",
    "         np.arange(1, 1.31, 0.03)][severity - 1]\n",
    "\n",
    "    x = (np.array(x) / 255.).astype(np.float32)\n",
    "    out = np.zeros_like(x)\n",
    "    for zoom_factor in c:\n",
    "        out += clipped_zoom(x, zoom_factor)\n",
    "\n",
    "    x = (x + out) / (len(c) + 1)\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def fog(x, severity=1):\n",
    "    c = [(1.5, 2), (2., 2), (2.5, 1.7), (2.5, 1.5), (3., 1.4)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    H, W, _ = x.shape\n",
    "    max_val = x.max()\n",
    "\n",
    "    heightmap = plasma_fractal(mapsize=256, wibbledecay=c[1])  # lav 256x256\n",
    "    # skaler til billedets dimensioner\n",
    "    heightmap = cv2.resize(heightmap, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "    heightmap = heightmap[..., np.newaxis]  # tilføj kanal\n",
    "\n",
    "    x += c[0] * heightmap\n",
    "    return np.clip(x * max_val / (max_val + c[0]), 0, 1) * 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spatter(x, severity=1):\n",
    "    c = [(0.65, 0.3, 4, 0.69, 0.6, 0),\n",
    "         (0.65, 0.3, 3, 0.68, 0.6, 0),\n",
    "         (0.65, 0.3, 2, 0.68, 0.5, 0),\n",
    "         (0.65, 0.3, 1, 0.65, 1.5, 1),\n",
    "         (0.67, 0.4, 1, 0.65, 1.5, 1)][severity - 1]\n",
    "    x = np.array(x, dtype=np.float32) / 255.\n",
    "\n",
    "    liquid_layer = np.random.normal(size=x.shape[:2], loc=c[0], scale=c[1])\n",
    "\n",
    "    liquid_layer = gaussian(liquid_layer, sigma=c[2])\n",
    "    liquid_layer[liquid_layer < c[3]] = 0\n",
    "    if c[5] == 0:\n",
    "        liquid_layer = (liquid_layer * 255).astype(np.uint8)\n",
    "        dist = 255 - cv2.Canny(liquid_layer, 50, 150)\n",
    "        dist = cv2.distanceTransform(dist, cv2.DIST_L2, 5)\n",
    "        _, dist = cv2.threshold(dist, 20, 20, cv2.THRESH_TRUNC)\n",
    "        dist = cv2.blur(dist, (3, 3)).astype(np.uint8)\n",
    "        dist = cv2.equalizeHist(dist)\n",
    "        ker = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n",
    "        dist = cv2.filter2D(dist, cv2.CV_8U, ker)\n",
    "        dist = cv2.blur(dist, (3, 3)).astype(np.float32)\n",
    "\n",
    "        m = cv2.cvtColor(liquid_layer * dist, cv2.COLOR_GRAY2BGRA)\n",
    "        m /= np.max(m, axis=(0, 1))\n",
    "        m *= c[4]\n",
    "\n",
    "        # water is pale turqouise\n",
    "        color = np.concatenate((175 / 255. * np.ones_like(m[..., :1]),\n",
    "                                238 / 255. * np.ones_like(m[..., :1]),\n",
    "                                238 / 255. * np.ones_like(m[..., :1])), axis=2)\n",
    "\n",
    "        color = cv2.cvtColor(color, cv2.COLOR_BGR2BGRA)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "        return cv2.cvtColor(np.clip(x + m * color, 0, 1), cv2.COLOR_BGRA2BGR) * 255\n",
    "    else:\n",
    "        m = np.where(liquid_layer > c[3], 1, 0)\n",
    "        m = gaussian(m.astype(np.float32), sigma=c[4])\n",
    "        m[m < 0.8] = 0\n",
    "\n",
    "        # mud brown\n",
    "        color = np.concatenate((63 / 255. * np.ones_like(x[..., :1]),\n",
    "                                42 / 255. * np.ones_like(x[..., :1]),\n",
    "                                20 / 255. * np.ones_like(x[..., :1])), axis=2)\n",
    "\n",
    "        color *= m[..., np.newaxis]\n",
    "        x *= (1 - m[..., np.newaxis])\n",
    "\n",
    "        return np.clip(x + color, 0, 1) * 255\n",
    "\n",
    "\n",
    "def contrast(x, severity=1):\n",
    "    c = [0.4, .3, .2, .1, .05][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    means = np.mean(x, axis=(0, 1), keepdims=True)\n",
    "    return np.clip((x - means) * c + means, 0, 1) * 255\n",
    "\n",
    "\n",
    "def brightness(x, severity=1):\n",
    "    c = [.1, .2, .3, .4, .5][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    x = sk.color.rgb2hsv(x)\n",
    "    x[:, :, 2] = np.clip(x[:, :, 2] + c, 0, 1)\n",
    "    x = sk.color.hsv2rgb(x)\n",
    "\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def saturate(x, severity=1):\n",
    "    c = [(0.3, 0), (0.1, 0), (2, 0), (5, 0.1), (20, 0.2)][severity - 1]\n",
    "\n",
    "    x = np.array(x) / 255.\n",
    "    x = sk.color.rgb2hsv(x)\n",
    "    x[:, :, 1] = np.clip(x[:, :, 1] * c[0] + c[1], 0, 1)\n",
    "    x = sk.color.hsv2rgb(x)\n",
    "\n",
    "    return np.clip(x, 0, 1) * 255\n",
    "\n",
    "\n",
    "def jpeg_compression(x, severity=1):\n",
    "    c = [25, 18, 15, 10, 7][severity - 1]\n",
    "\n",
    "    output = BytesIO()\n",
    "    x.save(output, 'JPEG', quality=c)\n",
    "    x = PILImage.open(output)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pixelate(x, severity=1):\n",
    "    c = [0.6, 0.5, 0.4, 0.3, 0.25][severity - 1]\n",
    "\n",
    "    x = x.resize((int(224 * c), int(224 * c)), PILImage.BOX)\n",
    "    x = x.resize((224, 224), PILImage.BOX)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# mod of https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "def elastic_transform(image, severity=1):\n",
    "    c = [(244 * 2, 244 * 0.7, 244 * 0.1),   # 244 should have been 224, but ultimately nothing is incorrect\n",
    "         (244 * 2, 244 * 0.08, 244 * 0.2),\n",
    "         (244 * 0.05, 244 * 0.01, 244 * 0.02),\n",
    "         (244 * 0.07, 244 * 0.01, 244 * 0.02),\n",
    "         (244 * 0.12, 244 * 0.01, 244 * 0.02)][severity - 1]\n",
    "\n",
    "    image = np.array(image, dtype=np.float32) / 255.\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "\n",
    "    # random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size,\n",
    "                       [center_square[0] + square_size, center_square[1] - square_size],\n",
    "                       center_square - square_size])\n",
    "    pts2 = pts1 + np.random.uniform(-c[2], c[2], size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    dx = (gaussian(np.random.uniform(-1, 1, size=shape[:2]),\n",
    "                   c[1], mode='reflect', truncate=3) * c[0]).astype(np.float32)\n",
    "    dy = (gaussian(np.random.uniform(-1, 1, size=shape[:2]),\n",
    "                   c[1], mode='reflect', truncate=3) * c[0]).astype(np.float32)\n",
    "    dx, dy = dx[..., np.newaxis], dy[..., np.newaxis]\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "    return np.clip(map_coordinates(image, indices, order=1, mode='reflect').reshape(shape), 0, 1) * 255\n",
    "\n",
    "\n",
    "# /////////////// End Corruptions ///////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b77fa4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'ddpm-segmentation/datasets\\gaussian_noise_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\gaussian_noise_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\gaussian_noise_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\shot_noise_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\shot_noise_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\shot_noise_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\impulse_noise_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\impulse_noise_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\impulse_noise_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\speckle_noise_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\speckle_noise_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\speckle_noise_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\gaussian_blur_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\gaussian_blur_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\gaussian_blur_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\glass_blur_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\glass_blur_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\glass_blur_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\defocus_blur_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\defocus_blur_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\defocus_blur_severity5' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\zoom_blur_severity1' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\zoom_blur_severity3' already exists, skipping...\n",
      "Dataset 'ddpm-segmentation/datasets\\zoom_blur_severity5' already exists, skipping...\n",
      "Created dataset 'ddpm-segmentation/datasets\\fog_severity1' with corruption 'fog', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\fog_severity3' with corruption 'fog', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\fog_severity5' with corruption 'fog', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\spatter_severity1' with corruption 'spatter', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\spatter_severity3' with corruption 'spatter', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\spatter_severity5' with corruption 'spatter', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\contrast_severity1' with corruption 'contrast', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\contrast_severity3' with corruption 'contrast', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\contrast_severity5' with corruption 'contrast', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\brightness_severity1' with corruption 'brightness', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\brightness_severity3' with corruption 'brightness', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\brightness_severity5' with corruption 'brightness', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\saturate_severity1' with corruption 'saturate', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\saturate_severity3' with corruption 'saturate', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\saturate_severity5' with corruption 'saturate', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\jpeg_compression_severity1' with corruption 'jpeg_compression', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\jpeg_compression_severity3' with corruption 'jpeg_compression', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\jpeg_compression_severity5' with corruption 'jpeg_compression', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\pixelate_severity1' with corruption 'pixelate', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\pixelate_severity3' with corruption 'pixelate', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\pixelate_severity5' with corruption 'pixelate', severity=5\n",
      "Created dataset 'ddpm-segmentation/datasets\\elastic_transform_severity1' with corruption 'elastic_transform', severity=1\n",
      "Created dataset 'ddpm-segmentation/datasets\\elastic_transform_severity3' with corruption 'elastic_transform', severity=3\n",
      "Created dataset 'ddpm-segmentation/datasets\\elastic_transform_severity5' with corruption 'elastic_transform', severity=5\n"
     ]
    }
   ],
   "source": [
    "def make_noisy_dataset(src_root, dst_root, corruption_func, severity=1):\n",
    "    # Tjek om dataset allerede findes og ikke er tomt\n",
    "    if os.path.exists(dst_root) and any(os.scandir(os.path.join(dst_root, \"train\"))):\n",
    "        print(f\"Dataset '{dst_root}' already exists, skipping...\")\n",
    "        return\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        src_dir = os.path.join(src_root, split)\n",
    "        dst_dir = os.path.join(dst_root, split)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        for img_path in sorted(glob.glob(os.path.join(src_dir, \"*.png\"))):\n",
    "            img = PILImage.open(img_path).convert(\"RGB\")\n",
    "\n",
    "            corrupted = corruption_func(img, severity=severity)\n",
    "            \n",
    "            if isinstance(corrupted, np.ndarray):\n",
    "                corrupted = PILImage.fromarray(np.uint8(np.clip(corrupted, 0, 255)))\n",
    "\n",
    "            corrupted.save(os.path.join(dst_dir, os.path.basename(img_path)))\n",
    "\n",
    "            # Kopier tilhørende label, hvis den findes\n",
    "            label_path = os.path.splitext(img_path)[0] + \".npy\"\n",
    "            if os.path.exists(label_path):\n",
    "                shutil.copy(label_path, os.path.join(dst_dir, os.path.basename(label_path)))\n",
    "\n",
    "    print(f\"Created dataset '{dst_root}' with corruption '{corruption_func.__name__}', severity={severity}\")\n",
    "\n",
    "\n",
    "# Liste over alle corruption-funktioner\n",
    "corruptions = [\n",
    "    gaussian_noise,\n",
    "    shot_noise,\n",
    "    impulse_noise,\n",
    "    speckle_noise,\n",
    "    gaussian_blur,\n",
    "    glass_blur,\n",
    "    defocus_blur,\n",
    "    zoom_blur,\n",
    "    fog,\n",
    "    spatter,\n",
    "    contrast,\n",
    "    brightness,\n",
    "    saturate,\n",
    "    jpeg_compression,\n",
    "    pixelate,\n",
    "    elastic_transform\n",
    "]\n",
    "\n",
    "# Severity levels, kun 1, 3 og 5\n",
    "severity_levels = [1, 3, 5]\n",
    "\n",
    "base = \"ddpm-segmentation/datasets\"\n",
    "src_root = os.path.join(base, \"horse_21/real\")\n",
    "\n",
    "# Loop over alle corruptioner og severity levels\n",
    "for corruption in corruptions:\n",
    "    for severity in severity_levels:\n",
    "        dst_root = os.path.join(base, f\"{corruption.__name__}_severity{severity}\")\n",
    "        make_noisy_dataset(src_root, dst_root, corruption_func=corruption, severity=severity)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atdl_a3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
